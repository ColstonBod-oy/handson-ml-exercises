{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Ohmls9bqAjjM",
      "metadata": {
        "id": "Ohmls9bqAjjM"
      },
      "source": [
        "**Chapter 2 â€“ End-to-end Machine Learning project**\n",
        "\n",
        "*Welcome to Machine Learning Housing Corp.! Your task is to predict median house values in Californian districts, given a number of features from these districts.*\n",
        "\n",
        "*This notebook contains all the sample code and solutions to the exercices in chapter 2.*\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ColstonBod-oy/handson-ml-exercises/blob/main/Housing.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dTqnO0dBAjkO",
      "metadata": {
        "id": "dTqnO0dBAjkO"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cAETnrXWC3UC",
      "metadata": {
        "id": "cAETnrXWC3UC"
      },
      "source": [
        "Using this chapter's housing dataset:\n",
        "\n",
        "\n",
        "1.   Try a Support Vector Machine regressor (`sklearn.svm.SVR`), with various hyperparameters such as `kernel=\"linear\"` (with various values for the `C` hyperparameter) or `kernel=\"rbf\"` (with various values for the `C` and `gamma` hyperparameters). Don't worry about what these hyperparameters mean for now. How does the best `SVR` predictor perform?\n",
        "\n",
        "2.   Try replacing `GridSearchCV` with `RandomizedSearchCV`.\n",
        "\n",
        "3.   Try adding a transformer in the preparation pipeline to select only the most important attributes.\n",
        "\n",
        "4.   Try creating a single pipeline that does the full data preparation plus the final prediction.\n",
        "\n",
        "5.   Automatically explore some preparation options using `GridSearchCV`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VMktCTX0AjjV",
      "metadata": {
        "id": "VMktCTX0AjjV"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "clJFVToSAjjV",
      "metadata": {
        "id": "clJFVToSAjjV"
      },
      "source": [
        "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "cJX4NnOtAjjW",
      "metadata": {
        "id": "cJX4NnOtAjjW"
      },
      "outputs": [],
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"end_to_end_project\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9_iNowFBAjjY",
      "metadata": {
        "id": "9_iNowFBAjjY"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "7EN72NCYAjja",
      "metadata": {
        "id": "7EN72NCYAjja"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ColstonBod-oy/handson-ml-exercises/main/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "rN1_pf-rAjjb",
      "metadata": {
        "id": "rN1_pf-rAjjb"
      },
      "outputs": [],
      "source": [
        "fetch_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "k9FZk71NAjjc",
      "metadata": {
        "id": "k9FZk71NAjjc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "yJgQyLgEAjjd",
      "metadata": {
        "id": "yJgQyLgEAjjd"
      },
      "outputs": [],
      "source": [
        "housing = load_housing_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "697N5_sNAjjh",
      "metadata": {
        "id": "697N5_sNAjjh"
      },
      "outputs": [],
      "source": [
        "# to make this notebook's output identical at every run\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use stratified sampling method on the data"
      ],
      "metadata": {
        "id": "8erJMRRHU-I0"
      },
      "id": "8erJMRRHU-I0"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "K-snGUPsAjjl",
      "metadata": {
        "id": "K-snGUPsAjjl"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FMXeiYYPAjjn",
      "metadata": {
        "id": "FMXeiYYPAjjn"
      },
      "source": [
        "**Warning**: in the book, I did not use `pd.cut()`. The `pd.cut()` solution gives the same result (except the labels are integers instead of floats), but it is simpler to understand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "hGJsc3lPAjjn",
      "metadata": {
        "id": "hGJsc3lPAjjn"
      },
      "outputs": [],
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "yooFEOdMAjjo",
      "metadata": {
        "id": "yooFEOdMAjjo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "OiO6_a7fAjjr",
      "metadata": {
        "id": "OiO6_a7fAjjr"
      },
      "outputs": [],
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "_WP_2IhlBJyU"
      },
      "outputs": [],
      "source": [
        "housing = strat_train_set.copy()"
      ],
      "id": "_WP_2IhlBJyU"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VD_o940qBJyX"
      },
      "outputs": [],
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "id": "VD_o940qBJyX"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}